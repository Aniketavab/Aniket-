{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "import plotnine\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import xgboost as xgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-property",
   "metadata": {},
   "source": [
    "After importing the data set into Python, the `df_train` is now our data frame. The data frame has a lot of functions and methods that will create spesific outputs about the characteristic of data frame. The method of `columns` will print out all the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('loan_prediction.csv',\n",
    "    usecols = [i for i in range(1, 14)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data dimension: {} rows and {} columns'.format(len(df_train), len(df_train.columns)))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    filepath_or_buffer = 'https://raw.githubusercontent.com/dphi-official/Datasets/master/Loan_Data/loan_test.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-retreat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Data dimension: {} rows and {} columns'.format(len(df_test), len(df_test.columns)))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-enclosure",
   "metadata": {},
   "source": [
    "The method of `info` will show us the metadata or information about the columns in a data frame. It undirectly specifies the scale measurement of a given columns in a data frame. However, it can be misleading. So, we must modify the scale measurement or column types based on column characteristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame metadata\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column types\n",
    "df_train = df_train.astype({'Credit_History': object, 'Loan_Status': int})\n",
    "df_train.select_dtypes(include = ['object']).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-leave",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summary statistics of categorical columns\n",
    "for i in df_train.select_dtypes('object').columns:\n",
    "    print(df_train[i].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-landscape",
   "metadata": {},
   "source": [
    "#### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-burden",
   "metadata": {},
   "source": [
    "**Note**: Consideration to remove missing values is based on a business logic. The concept of *garbage in garbage out* applies. Without any relevant domain knowledges of loan problem, the interpolation will lead to the biased result.\n",
    "\n",
    "Instead of dropping the missing values brutally, we try to inspect the relevant variables in the data in order to suggest the consideration for the next analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-staff",
   "metadata": {},
   "source": [
    "##### `Dependents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of missing dependents is about {} rows'.format(df_train['Dependents'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing valuess with \"0\"\n",
    "df_train['Dependents'].fillna(value = '0', inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-interpretation",
   "metadata": {},
   "source": [
    "##### `Self_Employed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of missing Self_Employed is about {} rows'.format(df_train['Self_Employed'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with \"No\"\n",
    "df_train['Self_Employed'].fillna(value = 'No', inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-tuner",
   "metadata": {},
   "source": [
    "##### `Loan_Amount_Term`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['Loan_Amount_Term', 'Loan_Status']].groupby('Loan_Status').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentile 20th: {}'.format(df_train['Loan_Amount_Term'].quantile(q = 0.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with \"360\"\n",
    "df_train['Loan_Amount_Term'].fillna(value = 360, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-cargo",
   "metadata": {},
   "source": [
    "##### `Credit_History`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross tabulation of credit history and loan status\n",
    "df_cred_hist = pd.crosstab(df_train['Credit_History'], df_train['Loan_Status'], margins = True).reset_index()\n",
    "# Remove index name\n",
    "df_cred_hist.columns.name = None\n",
    "# Remove last row for total column attribute\n",
    "df_cred_hist = df_cred_hist.drop([len(df_cred_hist) - 1], axis = 0)\n",
    "df_cred_hist.rename(columns = {'Credit_History':'Credit History', 0:'No', 1:'Yes'}, inplace = True)\n",
    "df_cred_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the data frame based on loan status\n",
    "pos_cred_hist0 = df_train[(df_train['Credit_History'].isna()) & (df_train['Loan_Status'] == 0)]\n",
    "pos_cred_hist1 = df_train[(df_train['Credit_History'].isna()) & (df_train['Loan_Status'] == 1)]\n",
    "print('Number of rows with Loan_Status is No but Credit_History is NaN  : {}'.format(len(pos_cred_hist0)))\n",
    "print('Number of rows with Loan_Status is Yes but Credit_History is NaN : {}'.format(len(pos_cred_hist1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values with a specific condition\n",
    "credit_loan = zip(df_train['Credit_History'], df_train['Loan_Status'])\n",
    "df_train['Credit_History'] = [\n",
    "                                0.0 if np.isnan(credit) and status == 0 else\n",
    "                                1.0 if np.isnan(credit) and status == 1 else\n",
    "                                credit for credit, status in credit_loan\n",
    "                             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-growth",
   "metadata": {},
   "source": [
    "##### `Gender` and `Loan Amount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "df_train.dropna(axis = 0, how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing value\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-fence",
   "metadata": {},
   "source": [
    "### Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-wright",
   "metadata": {},
   "source": [
    "#### Scale measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame metadata\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column types\n",
    "df_test = df_test.astype({'Credit_History': object})\n",
    "df_test.select_dtypes(include = ['object']).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-chair",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summary statistics of categorical columns\n",
    "for i in df_test.select_dtypes('object').columns:\n",
    "    print(df_test[i].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-light",
   "metadata": {},
   "source": [
    "#### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-member",
   "metadata": {},
   "source": [
    "##### `Dependents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of missing values in Dependents is about {} rows'.format(df_test['Dependents'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with \"0\"\n",
    "df_test['Dependents'].fillna(value = '0', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-canal",
   "metadata": {},
   "source": [
    "##### `Self_Employed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of missing values in Self_Employed is about {} rows'.format(df_test['Self_Employed'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with \"No\"\n",
    "df_test['Self_Employed'].fillna(value = 'No', inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-baseline",
   "metadata": {},
   "source": [
    "##### `Loan_Amount_Term`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with \"360\"\n",
    "df_test['Loan_Amount_Term'].fillna(value = 360, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-performer",
   "metadata": {},
   "source": [
    "##### `Gender`, `Married`, `LoanAmount` and `Credit_History`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "df_test.dropna(axis = 0, how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-collectible",
   "metadata": {},
   "source": [
    "## Explanatory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-dragon",
   "metadata": {},
   "source": [
    "### The composition of default and not default customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data aggregation between default and not default customers\n",
    "df_viz_1 = df_train.groupby(['Loan_Status'])['Loan_ID'].count().reset_index(name = 'Total')\n",
    "# Map the loan status\n",
    "df_viz_1['Loan_Status'] = df_viz_1['Loan_Status'].map(\n",
    "    {\n",
    "        0: 'Not default',\n",
    "        1: 'Default'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the data\n",
    "df_viz_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size\n",
    "plt.figure(figsize = (6.4,4.8))\n",
    "\n",
    "# Customize colors and other settings\n",
    "colors = ['#80797c','#981220']\n",
    "\n",
    "# Explode 1st slice\n",
    "explode = (0.1, 0)\n",
    "\n",
    "# Create a pie chart\n",
    "plt.pie(\n",
    "    x = 'Total',\n",
    "    labels = 'Loan_Status',\n",
    "    data = df_viz_1,\n",
    "    explode = explode,\n",
    "    colors = colors,\n",
    "    autopct = '%1.1f%%',\n",
    "    shadow = False,\n",
    "    startangle = 140\n",
    ")\n",
    "\n",
    "# Title and axis\n",
    "plt.title('Number of customers by loan status', fontsize = 18)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-clark",
   "metadata": {},
   "source": [
    "### The composition of loan status by the dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data aggregation between loan status and dependents\n",
    "df_viz_2 = df_train.groupby(['Loan_Status', 'Dependents'])['Loan_ID'].count().reset_index(name = 'Total')\n",
    "# Map the loan status\n",
    "df_viz_2['Loan_Status'] = df_viz_2['Loan_Status'].map(\n",
    "    {\n",
    "        0: 'Not default',\n",
    "        1: 'Default'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the data\n",
    "df_viz_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotnine.options.figure_size = (8, 4.8)\n",
    "(\n",
    "    ggplot(\n",
    "        data = df_viz_2\n",
    "    )+\n",
    "    geom_bar(\n",
    "        aes(\n",
    "            x = 'Dependents',\n",
    "            y = 'Total',\n",
    "            fill = 'Loan_Status'\n",
    "        ),\n",
    "        stat = 'identity',\n",
    "        position = 'fill',\n",
    "        width = 0.5\n",
    "    )+\n",
    "    labs(\n",
    "        title = 'The composition of loan status by the dependents',\n",
    "        fill = 'Loan status'\n",
    "    )+\n",
    "    xlab(\n",
    "        'Dependents'\n",
    "    )+\n",
    "    ylab(\n",
    "        'Frequency'\n",
    "    )+\n",
    "    scale_x_discrete(\n",
    "        limits = ['0', '1', '2', '3+']\n",
    "    )+\n",
    "    scale_fill_manual(\n",
    "        values = ['#981220','#80797c'],\n",
    "        labels = ['Default', 'Not Default']\n",
    "    )+\n",
    "    theme_minimal()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-haven",
   "metadata": {},
   "source": [
    "### The composition of default customer by the educations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data aggregation between loan status and dependents\n",
    "df_viz_3 = df_train.groupby(['Loan_Status', 'Education'])['Loan_ID'].count().reset_index(name = 'Total')\n",
    "# Map the loan status\n",
    "df_viz_3['Loan_Status'] = df_viz_3['Loan_Status'].map(\n",
    "    {\n",
    "        0: 'Not default',\n",
    "        1: 'Default'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the data\n",
    "df_viz_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotnine.options.figure_size = (8, 4.8)\n",
    "(\n",
    "    ggplot(\n",
    "        data = df_viz_3\n",
    "    )+\n",
    "    geom_bar(\n",
    "        aes(\n",
    "            x = 'Education',\n",
    "            y = 'Total',\n",
    "            fill = 'Loan_Status'\n",
    "        ),\n",
    "        stat = 'identity',\n",
    "        position = 'fill',\n",
    "        width = 0.5\n",
    "    )+\n",
    "    labs(\n",
    "        title = 'The composition of loan status by the education',\n",
    "        fill = 'Loan status'\n",
    "    )+\n",
    "    xlab(\n",
    "        'Educations'\n",
    "    )+\n",
    "    ylab(\n",
    "        'Frequency'\n",
    "    )+\n",
    "    scale_x_discrete(\n",
    "        limits = ['Graduate', 'Not Graduate']\n",
    "    )+\n",
    "    scale_fill_manual(\n",
    "        values = ['#981220','#80797c'],\n",
    "        labels = ['Default', 'Not Default']\n",
    "    )+\n",
    "    theme_minimal()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-engine",
   "metadata": {},
   "source": [
    "### The distribution of applicant incomes by loan status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the columns\n",
    "df_viz_4 = df_train[['ApplicantIncome', 'Loan_Status']].reset_index(drop = True)\n",
    "# Map the loan status\n",
    "df_viz_4['Loan_Status'] = df_viz_4['Loan_Status'].map(\n",
    "    {\n",
    "        0: 'Not default',\n",
    "        1: 'Default'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the data\n",
    "df_viz_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotnine.options.figure_size = (8, 4.8)\n",
    "(\n",
    "    ggplot(\n",
    "        data = df_viz_4\n",
    "    )+\n",
    "    geom_density(\n",
    "        aes(\n",
    "            x = 'ApplicantIncome',\n",
    "            fill = 'Loan_Status'\n",
    "        ),\n",
    "        color = 'white',\n",
    "        alpha = 0.85\n",
    "    )+\n",
    "    labs(\n",
    "        title = 'The distribution of applicant incomes by loan status'\n",
    "    )+\n",
    "    scale_fill_manual(\n",
    "        name = 'Loan Status',\n",
    "        values = ['#981220','#80797c'],\n",
    "        labels = ['Default', 'Not Default']\n",
    "    )+\n",
    "    xlab(\n",
    "        'Applicant income'\n",
    "    )+\n",
    "    ylab(\n",
    "        'Density'\n",
    "    )+\n",
    "    theme_minimal()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-invalid",
   "metadata": {},
   "source": [
    "### The distribution of loan amount by loan status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the columns\n",
    "df_viz_5 = df_train[['LoanAmount', 'Loan_Status']].reset_index(drop = True)\n",
    "# Map the loan status\n",
    "df_viz_5['Loan_Status'] = df_viz_5['Loan_Status'].map(\n",
    "    {\n",
    "        0: 'Not default',\n",
    "        1: 'Default'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the data\n",
    "df_viz_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotnine.options.figure_size = (8, 4.8)\n",
    "(\n",
    "    ggplot(\n",
    "        data = df_viz_5\n",
    "    )+\n",
    "    geom_density(\n",
    "        aes(\n",
    "            x = 'LoanAmount',\n",
    "            fill = 'Loan_Status'\n",
    "        ),\n",
    "        color = 'white',\n",
    "        alpha = 0.85\n",
    "    )+\n",
    "    labs(\n",
    "        title = 'The distribution of loan amount by loan status'\n",
    "    )+\n",
    "    scale_fill_manual(\n",
    "        name = 'Loan Status',\n",
    "        values = ['#981220','#80797c'],\n",
    "        labels = ['Default', 'Not Default']\n",
    "    )+\n",
    "    xlab(\n",
    "        'Loan amount'\n",
    "    )+\n",
    "    ylab(\n",
    "        'Density'\n",
    "    )+\n",
    "    theme_minimal()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-sussex",
   "metadata": {},
   "source": [
    "## One-hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column of Loan_Status with 999 in testing data\n",
    "df_test['Loan_Status'] = 999\n",
    "# Concat the training and testing data\n",
    "df_concat = pd.concat(objs = [df_train , df_test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column of Loan_ID\n",
    "df_concat.drop(columns = ['Loan_ID'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns\n",
    "cols_obj_train = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
    "print(cols_obj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-accountability",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "df_concat = pd.get_dummies(data = df_concat, columns = cols_obj_train, drop_first = True)\n",
    "print('Dimension data: {} rows and {} columns'.format(len(df_concat), len(df_concat.columns)))\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-occasion",
   "metadata": {},
   "source": [
    "## Data partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values of Loan_Status\n",
    "df_concat['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-collar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training set\n",
    "df_train = df_concat[df_concat['Loan_Status'].isin([0, 1])].reset_index(drop = True)\n",
    "print('Dimension data: {} rows and {} columns'.format(len(df_train), len(df_train.columns)))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-reality",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing set\n",
    "df_test = df_concat[df_concat['Loan_Status'].isin([999])].reset_index(drop = True)\n",
    "print('Data dimension: {} rows and {} columns'.format(len(df_test), len(df_test.columns)))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data partitioning >>> training set into training and validation\n",
    "df_train_final = df_train.reset_index(drop = True)\n",
    "X = df_train_final[df_train_final.columns[~df_train_final.columns.isin(['Loan_Status'])]]\n",
    "y = df_train_final['Loan_Status']\n",
    "\n",
    "# Training = 70% and validation = 30%\n",
    "X_train, X_val, y_train, y_val = train_test_split(X , y, test_size = 0.3, random_state = 42)\n",
    "print('Data dimension of training set   :', X_train.shape)\n",
    "print('Data dimension of validation set :', X_val.shape)\n",
    "\n",
    "# Testing set\n",
    "X_test = df_test[df_test.columns[~df_test.columns.isin(['Loan_Status'])]]\n",
    "print('Data dimension of testing set    :', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-probability",
   "metadata": {},
   "source": [
    "## Machine learning model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective = 'binary:logistic',\n",
    "    use_label_encoder = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter range \n",
    "params = {\n",
    "    'eta': np.arange(0.1, 0.26, 0.05),\n",
    "    'min_child_weight': np.arange(1, 5, 0.5).tolist(),\n",
    "    'gamma': [5],\n",
    "    'subsample': np.arange(0.5, 1.0, 0.11).tolist(),\n",
    "    'colsample_bytree': np.arange(0.5, 1.0, 0.11).tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scorer from a performance metric or loss function\n",
    "scorers = {\n",
    "    'f1_score': make_scorer(f1_score),\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "skf = KFold(n_splits = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the grid search CV\n",
    "grid = GridSearchCV(\n",
    "    estimator = xgb_model,\n",
    "    param_grid = params,\n",
    "    scoring = scorers,\n",
    "    n_jobs = -1,\n",
    "    cv = skf.split(X_train, np.array(y_train)),\n",
    "    refit = 'accuracy_score'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "grid.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction of training \n",
    "predicted = grid.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-offense",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model evaluation - training data\n",
    "accuracy_baseline = accuracy_score(predicted, np.array(y_val))\n",
    "recall_baseline = recall_score(predicted, np.array(y_val))\n",
    "precision_baseline = precision_score(predicted, np.array(y_val))\n",
    "f1_baseline = f1_score(predicted, np.array(y_val))\n",
    "\n",
    "print('Accuracy for baseline   :{}'.format(round(accuracy_baseline, 5)))\n",
    "print('Recall for baseline     :{}'.format(round(recall_baseline, 5)))\n",
    "print('Precision for baseline  :{}'.format(round(precision_baseline, 5)))\n",
    "print('F1 Score for baseline   :{}'.format(round(f1_baseline, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-intersection",
   "metadata": {},
   "source": [
    "## Store the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the model into a pickle file\n",
    "filename = '../bin/xgboostModel.pkl'\n",
    "joblib.dump(grid.best_estimator_, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5b689-f4ba-41d2-87af-08a3ed7ad2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9724b0d-c68c-4e5a-9167-f6fa18b5100d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7933a-68b7-46a8-a0c3-4fa113df2cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f9542-3a6b-49a6-bfe2-7fcef866160a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd7b965-2ed4-4d79-b7d0-6344e1fbad77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d6c17-f714-4aa3-8dea-5c4ef4e0f0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584a2a96-e047-43d1-95b4-215134d9027c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec6f97-df4a-4490-b46d-011bab87f9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391dbb73-0006-4f52-9b94-7a9782f04153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1c5660-94e5-49a8-9f98-c59d6bd37a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a85d9-4d21-4b67-a31a-3ebb8d367257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbdd778-a450-4818-95de-c39448760fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c7b971-2a94-4753-8e95-9b438fc753bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d29356-d5df-4b80-9860-8fc9af43c908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdcee7f-9000-40d0-951f-f7f46bd96178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188a97d-daa3-4fb2-b272-351e41cba88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4571f-fb0a-4676-bf5c-8f9194dff054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b3219-70b8-4464-9a9e-0cd4ca3b82c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4bc3bb-eaba-4e6f-b437-0189cfd14ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48059c-bf37-4c3d-8b25-7c56cc7f0264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72536103-10e2-40ff-93d5-856ddacb64cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465355d0-664d-4bb7-b3de-93c08b53c3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5b3bb-e060-4553-8654-5c29ceb099fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc602da-8a5e-417c-819b-4d60b47cd370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c868c0-8016-4a94-ad20-2d0d9c5f3acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e2845-6a8a-4133-833c-11f40301233e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32801ff1-cd87-4884-911c-0e88ea40ec88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba947d54-dac4-453c-b303-56705883942e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276379a7-8b7b-4503-b3f9-cce17f7a884b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df4aa7a-fdcb-43d1-812b-48e74e9adceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e11ef0-1691-4527-bfe6-adf72aa56ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd08f29a-d2c6-4949-88e2-04da9f7f095f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1741a-f9f5-4348-9c34-76749bee8047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb20847-4c27-4b35-b5d5-11cd8032448e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac92bf-81e4-498c-865c-ad980675dff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360d0ad-2856-4a29-907c-1b85aa9a8a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
